{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "#np.warnings.filterwarnings('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from tensorflow.contrib.eager.python import tfe\n",
        "from PIL import Image\n",
        "\n",
        "#tf.enable_eager_execution()\n",
        "#tf.set_random_seed(0)\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "NLlg0bRM5eHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/fc-cnn-assignment.zip"
      ],
      "metadata": {
        "id": "TeNb1m7R7AfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/train.csv')\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "yrRKcBI45g7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZCzgpcPB7HJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "id": "PtmjlmqJ5ix7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset:\n",
        "    def __init__(self, data, label):\n",
        "        self.data = data\n",
        "        self.label = label\n",
        "        self.w = 224\n",
        "        self.h = 224\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        image = cv2.imread(self.data[i])\n",
        "        image = cv2.resize(image, (self.w, self.h))\n",
        "        image = np.array(image, dtype='float32')/255\n",
        "        label = self.label[i]  # Chỉnh sửa: Lấy nhãn tương ứng với ảnh\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "4NR3UdQL5l4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataloader(tf.keras.utils.Sequence):\n",
        "    def __init__(self, dataset, batch_size, size):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.size = size\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = min((i + 1) * self.batch_size, len(self.dataset))  # Chỉnh sửa: Xử lý chỉ mục kết thúc\n",
        "        data = [self.dataset[j] for j in range(start, stop)]\n",
        "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
        "        return tuple(batch)\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.size + self.batch_size - 1) // self.batch_size  # Chỉnh sửa: Tính toán số lượng batch"
      ],
      "metadata": {
        "id": "YYx6OLu05n10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List các đường dẫn file cho việc huấn luyện\n",
        "train_files = [os.path.join(\"/content/images/images\", file) for file in train_df.image]\n",
        "\n",
        "# List các nhãn\n",
        "train_y = train_df.label"
      ],
      "metadata": {
        "id": "CpQ8nKMT5qB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(np.unique(train_y))\n",
        "y_ohe = tf.keras.utils.to_categorical(train_y, num_classes=num_classes)"
      ],
      "metadata": {
        "id": "gQKuMbBb5s2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_valid, y_train_ohe, y_valid_ohe = train_test_split(train_files, y_ohe, test_size=0.25)"
      ],
      "metadata": {
        "id": "ySdUfnIg5u8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset(x_train, y_train_ohe)\n",
        "valid_dataset = Dataset(x_valid,y_valid_ohe)\n",
        "train_loader = Dataloader(train_dataset, 64, len(train_dataset))\n",
        "valid_loader = Dataloader(valid_dataset, 64, len(valid_dataset))\n"
      ],
      "metadata": {
        "id": "sfd8WYuV5w7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFFPyltN5WXF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Tải mô hình VGG16 đã được huấn luyện sẵn, không bao gồm tầng fully connected cuối cùng\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze các layer của mô hình base\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Thêm các layer tùy chỉnh của bạn\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Thêm Dropout để tránh overfitting\n",
        "predictions = Dense(num_classes, activation='softmax')(x)  # num_classes là số lớp bạn muốn phân loại\n",
        "\n",
        "# Tạo model cuối cùng\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer= tf.optimizers.SGD(learning_rate=0.001,\\\n",
        "                momentum=0.9,weight_decay=0.0005), metrics=['accuracy'])\n",
        "    # Huấn luyện\n",
        "\n",
        "history=model.fit(train_loader, validation_data=valid_loader, epochs=100, verbose=1)\n",
        "model.save('my_model', save_format='tf')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the model results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        "print(max(acc))\n",
        "print(max(val_acc))\n",
        "print(min(loss))\n",
        "print(min(val_loss))\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('VVG16_pretrained: Training and validation accuracy')\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('VVG16_pretrained:Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7gURXLZz6dSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = Alex_net(num_classes)\n",
        "#dummy_x = tf.zeros((1, 224, 224, 3))\n",
        "#model._set_inputs(dummy_x)\n",
        "loaded_model = tf.keras.models.load_model('my_model')\n",
        "print(\"Model đã được load\")"
      ],
      "metadata": {
        "id": "9EeuW4yl6eru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "y=0\n",
        "f1=[]\n",
        "for i in x_valid:\n",
        "  image = cv2.imread(i)\n",
        "  image= cv2.resize(image,(224,224))\n",
        "  print(image.shape)\n",
        "  image = tf.cast(image, tf.float32) / 255.0\n",
        "  image = tf.expand_dims(image, axis=0)\n",
        "  pred = loaded_model.predict(image)\n",
        "  pred_labels = np.argmax(pred, axis=1)\n",
        "  y_pre_test = tf.keras.utils.to_categorical(pred_labels, num_classes=11)\n",
        "  f1.append(f1_score(y_pre_test.squeeze(),np.array(y_valid_ohe[y])))\n",
        "  y=y+1"
      ],
      "metadata": {
        "id": "GmhehEq06gwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1=np.mean(f1)\n",
        "print(f\"f1 Score:{f1}\")"
      ],
      "metadata": {
        "id": "3K7g50Axcp07"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}